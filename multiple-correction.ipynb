{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats.multitest as smm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test a simulated hypothesis based on the data drown from standard normal distribution.\n",
    "\n",
    "<b>H0</b>: value of x is not different from 0\n",
    "\n",
    "<b>H1</b>: value of x is larger than 0\n",
    "\n",
    "The first 900 observations should fail to reject the null hypothesis: they are, in fact, drawn from a standard normal distribution and any 2 difference between the observed value and 0 is just due to chance. \n",
    "\n",
    "The last 100 observations should reject the null hypothesis: the difference between these values and 0 is not due to\n",
    "chance alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numtests = 1000\n",
    "alpha = 0.05\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n",
      "  1.57921282  0.76743473 -0.46947439  0.54256004]\n"
     ]
    }
   ],
   "source": [
    "d1 = np.random.normal(0, 1, 900)\n",
    "d2 = np.random.normal(3, 1, 100)\n",
    "data1 = np.concatenate((d1, d2), axis=0)\n",
    "print(data1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = st.norm.rvs(0, 1, size=900)\n",
    "d4 = st.norm.rvs(2, 1, size=100)\n",
    "data2 = np.concatenate((d3, d4), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35264231  0.39514715  0.32345711  0.12508666  0.38815426  0.38815575\n",
      "  0.11464727  0.29718021  0.35731354  0.34434052]\n"
     ]
    }
   ],
   "source": [
    "prob = st.norm.pdf(data1)\n",
    "print(prob[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "test = prob > alpha\n",
    "print(test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 865\n",
      "False: 35\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in test[:900]]))\n",
    "print(\"False: %d\" % sum([not t for t in test[:900]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 18\n",
      "False: 82\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in test[900:]]))\n",
    "print(\"False: %d\" % sum([not t for t in test[900:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type I error rate: 0.0389\n",
      "Type II error rate: 0.1800\n"
     ]
    }
   ],
   "source": [
    "print(\"Type I error rate: %.4f\" % (sum([not t for t in test[:900]]) / 900.))\n",
    "print(\"Type II error rate: %.4f\" % (sum([t for t in test[900:]]) / 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonferroni correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonf_test = prob > alpha/numtests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from statsmodels.stats.multitest\n",
    "# rej, pval_corr = smm.multipletests(prob, alpha=0.05, method='b')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 900\n",
      "False: 0\n",
      "True: 88\n",
      "False: 12\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in bonf_test[:900]]))\n",
    "print(\"False: %d\" % sum([not t for t in bonf_test[:900]]))\n",
    "\n",
    "print(\"True: %d\" % sum([t for t in bonf_test[900:]]))\n",
    "print(\"False: %d\" % sum([not t for t in bonf_test[900:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type I error rate: 0.0000\n",
      "Type II error rate: 0.8800\n"
     ]
    }
   ],
   "source": [
    "print(\"Type I error rate: %.4f\" % (sum([not t for t in bonf_test[:900]]) / 900.))\n",
    "print(\"Type II error rate: %.4f\" % (sum([t for t in bonf_test[900:]]) / 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False discovery rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_sorted = np.sort(prob)\n",
    "\n",
    "fdrtest = None\n",
    "for i in range(numtests):\n",
    "    #print(next((i for i,x in enumerate(prob_sorted) if x == prob[i]), None))\n",
    "    position_value = prob[i] > next(i for i,x in enumerate(prob_sorted) if x == prob[i]) * alpha/numtests\n",
    "    fdrtest = np.append(fdrtest, position_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 896\n",
      "False: 3\n",
      "True: 51\n",
      "False: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in fdrtest[1:900]]))\n",
    "print(\"False: %d\" % sum([not t for t in fdrtest[1:900]]))\n",
    "\n",
    "print(\"True: %d\" % sum([t for t in fdrtest[900:]]))\n",
    "print(\"False: %d\" % sum([not t for t in fdrtest[900:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type I error rate: 0.0044\n",
      "Type II error rate: 0.5100\n"
     ]
    }
   ],
   "source": [
    "print(\"Type I error rate: %.4f\" % (sum([not t for t in fdrtest[:900]]) / 900.))\n",
    "print(\"Type II error rate: %.4f\" % (sum([t for t in fdrtest[900:]]) / 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benjamini/Hochberg (non-negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rej, pval_corr = smm.multipletests(prob, alpha=0.05, method='fdr_i')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_nn_test = pval_corr > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 898\n",
      "False: 2\n",
      "True: 52\n",
      "False: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in bh_nn_test[:900]]))\n",
    "print(\"False: %d\" % sum([not t for t in bh_nn_test[:900]]))\n",
    "\n",
    "print(\"True: %d\" % sum([t for t in bh_nn_test[900:]]))\n",
    "print(\"False: %d\" % sum([not t for t in bh_nn_test[900:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# two staged\n",
    "rej, pval_corr = smm.multipletests(prob, alpha=0.05, method='fdr_tsbh')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bh_nn_test_2 = pval_corr > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 898\n",
      "False: 2\n",
      "True: 52\n",
      "False: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in bh_nn_test_2[:900]]))\n",
    "print(\"False: %d\" % sum([not t for t in bh_nn_test_2[:900]]))\n",
    "\n",
    "print(\"True: %d\" % sum([t for t in bh_nn_test_2[900:]]))\n",
    "print(\"False: %d\" % sum([not t for t in bh_nn_test_2[900:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benjamini/Yekutieli (negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "rej, pval_corr = smm.multipletests(prob, alpha=0.05, method='fdr_n')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_n_test = pval_corr > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 865\n",
      "False: 35\n",
      "True: 18\n",
      "False: 82\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in test[:900]]))\n",
    "print(\"False: %d\" % sum([not t for t in test[:900]]))\n",
    "\n",
    "print(\"True: %d\" % sum([t for t in test[900:]]))\n",
    "print(\"False: %d\" % sum([not t for t in test[900:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benjamini/Krieger/Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rej, pval_corr = smm.multipletests(prob, alpha=0.05, method='fdr_tsbky')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bky_test = pval_corr > 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 898\n",
      "False: 2\n",
      "True: 52\n",
      "False: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"True: %d\" % sum([t for t in bky_test[:900]]))\n",
    "print(\"False: %d\" % sum([not t for t in bky_test[:900]]))\n",
    "\n",
    "print(\"True: %d\" % sum([t for t in bky_test[900:]]))\n",
    "print(\"False: %d\" % sum([not t for t in bky_test[900:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Should we correct primary and secondary goals separately?</b>\n",
    "\n",
    "There are two possibilities for the correction:\n",
    "1. Across all KPI and subgroups\n",
    "2. Correction per KPI\n",
    "\n",
    "Currently, the second approach seems to be more reasonable:\n",
    "- each KPI is a separate hypothesis (many of KPIs are independent of each other and don't share the same effect (good if uplift, good if down-lift))\n",
    "- significance is decided within each KPI, so that the more subgroups you have in terms of one KPI there will be more likelihood to get at least one significant result, which is the reason for correction.\n",
    "- for the final outcome we define recommendation rules (decides the resulting acceptance criteria across primary and secondary KPIs)\n",
    "\n",
    "\n",
    "First approach makes sense if KPIs are positively correlate with each other, share same effect and whether we want to replace the acceptance criteria.\n",
    "One of the drawbacks is that correction across all kpi-groups will adjust α to be very small. It will be impossible to remove one of the KPI from the decision.\n",
    "\n",
    "<b>2. Which correction should we use and why?</b>\n",
    "\n",
    "<b>Bonferroni correction</b>:\n",
    "+ it sets the significance cut-off at α/n, where n is the number of experiments.\n",
    "+ simplest and straigtforward correction.\n",
    "- it may be very conservative (assumes all tests are independent of each other), which may lead to a high rate of false negatives.\n",
    "- is not applicable if there is a positive correlation between tests.\n",
    "\n",
    "<b>The False Discovery Rate</b>:\n",
    "is the proportion of false positives among all significant results.\n",
    "The FDR works by estimating some rejection region so that, on average, FDR < α.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
