{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats.multitest as smm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_error_rates(test, start):\n",
    "    print(\"True: %d\" % sum([t for t in test[start:900]]))\n",
    "    print(\"False: %d\" % sum([not t for t in test[start:900]]))\n",
    "\n",
    "    print(\"True: %d\" % sum([t for t in test[900:]]))\n",
    "    print(\"False: %d\" % sum([not t for t in test[900:]]))\n",
    "    \n",
    "    \n",
    "    print(\"Type I error rate: %.4f\" % (sum([not t for t in test[:900]]) / 900.))\n",
    "    print(\"Type II error rate: %.4f\" % (sum([t for t in test[900:]]) / 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test a simulated hypothesis based on the data drown from standard normal distribution.\n",
    "\n",
    "<b>H0</b>: value of x is not different from 0\n",
    "\n",
    "<b>H1</b>: value of x is larger than 0\n",
    "\n",
    "The first 900 observations should fail to reject the null hypothesis: they are, in fact, drawn from a standard normal distribution and any 2 difference between the observed value and 0 is just due to chance. \n",
    "\n",
    "The last 100 observations should reject the null hypothesis: the difference between these values and 0 is not due to\n",
    "chance alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numtests = 1000\n",
    "alpha = 0.05\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49671415 -0.1382643   0.64768854  1.52302986 -0.23415337 -0.23413696\n",
      "  1.57921282  0.76743473 -0.46947439  0.54256004]\n"
     ]
    }
   ],
   "source": [
    "d1 = np.random.normal(0, 1, 900)\n",
    "d2 = np.random.normal(3, 1, 100)\n",
    "data1 = np.concatenate((d1, d2), axis=0)\n",
    "print(data1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = st.norm.rvs(0, 1, size=900)\n",
    "d4 = st.norm.rvs(2, 1, size=100)\n",
    "data2 = np.concatenate((d3, d4), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.35264231  0.39514715  0.32345711  0.12508666  0.38815426  0.38815575\n",
      "  0.11464727  0.29718021  0.35731354  0.34434052]\n"
     ]
    }
   ],
   "source": [
    "prob = st.norm.pdf(data1)\n",
    "print(prob[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "test = prob > alpha\n",
    "print(test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 865\n",
      "False: 35\n",
      "True: 18\n",
      "False: 82\n",
      "Type I error rate: 0.0389\n",
      "Type II error rate: 0.1800\n"
     ]
    }
   ],
   "source": [
    "print_error_rates(test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonferroni correction. Family-wise error rate (FWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Denote by $p_{i}$ the p-value for testing $H_{i}$\n",
    "2. Reject $H_{i}$ if $p_{i} \\le \\frac{\\alpha}{m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-05\n"
     ]
    }
   ],
   "source": [
    "bonf_test = prob > alpha/numtests\n",
    "print(alpha/numtests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from statsmodels.stats.multitest\n",
    "# rej, pval_corr = smm.multipletests(prob, alpha=0.05, method='b')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 900\n",
      "False: 0\n",
      "True: 88\n",
      "False: 12\n",
      "Type I error rate: 0.0000\n",
      "Type II error rate: 0.8800\n"
     ]
    }
   ],
   "source": [
    "print_error_rates(bonf_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decreased the <b>Type I error (true positives)</b> but increased the <b>Type II error (false negatives)</b>. Here the question is, depending on the context of the problem what type of error should we decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False discovery rate (FDR). Holm's step-down procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Order p-values in increasing order $P_{(1)} \\dots P_{(m)}$ and let the associated hypotheses be $H_{(1)} \\dots H_{(m)}$\n",
    "2. Let k be the minimal index such that :\n",
    "$$P_{(k)} > \\frac{\\alpha}{m+1-k}$$\n",
    "3. Reject the null hypotheses $H_{(1)} \\dots H_{(k-1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_sorted = np.sort(prob)\n",
    "\n",
    "fdrtest = None\n",
    "for i in range(numtests):\n",
    "    position_value = prob[i] > next(i for i,x in enumerate(prob_sorted) if x == prob[i]) * alpha/numtests\n",
    "    fdrtest = np.append(fdrtest, position_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 896\n",
      "False: 3\n",
      "True: 51\n",
      "False: 50\n",
      "Type I error rate: 0.0044\n",
      "Type II error rate: 0.5100\n"
     ]
    }
   ],
   "source": [
    "print_error_rates(fdrtest, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FWER control exerts a more stringent control over false discovery compared to false discovery rate (FDR) procedures. FWER control limits the probability of at least one false discovery, whereas FDR control limits (in a loose sense) the expected proportion of false discoveries. Thus, FDR procedures have greater power at the cost of increased rates of type I errors, i.e., rejecting null hypotheses that are actually true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benjamini/Hochberg (non-negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 898\n",
      "False: 2\n",
      "True: 52\n",
      "False: 48\n",
      "Type I error rate: 0.0022\n",
      "Type II error rate: 0.5200\n"
     ]
    }
   ],
   "source": [
    "rej_bh_nn, pval_corr_bh_nn = smm.multipletests(prob, alpha=0.05, method='fdr_i')[:2]\n",
    "bh_nn_test = pval_corr_bh_nn > 0.05\n",
    "\n",
    "print_error_rates(bh_nn_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 898\n",
      "False: 2\n",
      "True: 52\n",
      "False: 48\n",
      "Type I error rate: 0.0022\n",
      "Type II error rate: 0.5200\n"
     ]
    }
   ],
   "source": [
    "# two staged\n",
    "rej_bn_nn_2, pval_corr_bn_nn_2 = smm.multipletests(prob, alpha=0.05, method='fdr_tsbh')[:2]\n",
    "bh_nn_test_2 = pval_corr_bn_nn_2 > 0.05\n",
    "\n",
    "print_error_rates(bh_nn_test_2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benjamini/Yekutieli (negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 900\n",
      "False: 0\n",
      "True: 85\n",
      "False: 15\n",
      "Type I error rate: 0.0000\n",
      "Type II error rate: 0.8500\n"
     ]
    }
   ],
   "source": [
    "rej_by_n, pval_corr_by_n = smm.multipletests(prob, alpha=0.05, method='fdr_n')[:2]\n",
    "by_n_test = pval_corr_by_n > 0.05\n",
    "\n",
    "print_error_rates(by_n_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benjamini/Krieger/Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 898\n",
      "False: 2\n",
      "True: 52\n",
      "False: 48\n",
      "Type I error rate: 0.0022\n",
      "Type II error rate: 0.5200\n"
     ]
    }
   ],
   "source": [
    "rej_bky, pval_corr_bky = smm.multipletests(prob, alpha=0.05, method='fdr_tsbky')[:2]\n",
    "bky_test = pval_corr_bky > 0.05\n",
    "\n",
    "print_error_rates(bky_test, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Should we correct primary and secondary goals separately?</b>\n",
    "\n",
    "There are two possibilities for the correction:\n",
    "1. Across all KPI and subgroups\n",
    "2. Correction per KPI\n",
    "\n",
    "Currently, the second approach seems to be more reasonable:\n",
    "- each KPI is a separate hypothesis (many of KPIs are independent of each other and don't share the same effect (good if uplift, good if down-lift))\n",
    "- significance is decided within each KPI, so that the more subgroups you have in terms of one KPI there will be more likelihood to get at least one significant result, which is the reason for correction.\n",
    "- for the final outcome we define recommendation rules (decides the resulting acceptance criteria across primary and secondary KPIs)\n",
    "\n",
    "\n",
    "First approach makes sense if KPIs are positively correlate with each other, share same effect and whether we want to replace the acceptance criteria.\n",
    "One of the drawbacks is that correction across all kpi-groups will adjust α to be very small. It will be impossible to remove one of the KPI from the decision.\n",
    "\n",
    "<b>2. Which correction should we use and why?</b>\n",
    "\n",
    "<b>Bonferroni correction</b>:\n",
    "+ it sets the significance cut-off at α/n, where n is the number of experiments.\n",
    "+ simplest and straigtforward correction.\n",
    "- it may be very conservative (assumes all tests are independent of each other), which may lead to a high rate of false negatives.\n",
    "- is not applicable if there is a positive correlation between tests.\n",
    "\n",
    "<b>The False Discovery Rate</b>:\n",
    "is the proportion of false positives among all significant results.\n",
    "The FDR works by estimating some rejection region so that, on average, FDR < α.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
